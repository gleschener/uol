{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in /anaconda3/lib/python3.7/site-packages (0.3.0)\n",
      "Requirement already satisfied: Pillow in /anaconda3/lib/python3.7/site-packages (from pytesseract) (6.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: Gitpython in /anaconda3/lib/python3.7/site-packages (3.0.4)\n",
      "Requirement already satisfied: gitdb2>=2.0.0 in /anaconda3/lib/python3.7/site-packages (from Gitpython) (2.0.6)\n",
      "Requirement already satisfied: smmap2>=2.0.0 in /anaconda3/lib/python3.7/site-packages (from gitdb2>=2.0.0->Gitpython) (2.0.5)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import requests, time,shlex,subprocess\n",
    "import mimetypes as mim\n",
    "import base64\n",
    "from matplotlib.pyplot import imread\n",
    "import re\n",
    "page = 1\n",
    "res =[]\n",
    "from PIL import Image,ImageFile\n",
    "import numpy as np\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "!pip3 install pytesseract\n",
    "!pip3 install  Gitpython\n",
    "import pytesseract\n",
    "import git\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get('https://api.github.com/search/repositories?q=microservice+stars%3A521&type=Repositories&ref=advsearch&l=&l=+str(page)',auth=('gess18','3de21fec1f9d02f5f573c7bf9224cc8f22c6abeb'))\n",
    "res = req.json()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for contents\n",
    "def check_text(typeGuess):\n",
    "    if(re.search(typeGuess[0],'text') or re.search(typeGuess[1],'json') or re.search(typeGuess[1],'javascript')):\n",
    "         return True\n",
    "    else:\n",
    "         return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get type and check if image\n",
    "def check_img(typeGuess):\n",
    "    print()\n",
    "    if(re.search(typeGuess[0],'image')):\n",
    "         return True\n",
    "    else:\n",
    "         return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    repos=res['items']\n",
    "    print(len(repos))\n",
    "    for repoIndx in range(0, len(repos)):\n",
    "            repoName=repos[repoIndx]['full_name'].split('/')[1]\n",
    "            #We will the contents link for repo by using 'content_url' key.\n",
    "            gitsUrl = repos[repoIndx]['git_url']\n",
    "            print(gitsUrl.split(':')[1])\n",
    "            if(os.path.isdir(repos[repoIndx]['full_name'].split('/')[-2])==False):\n",
    "                       os.mkdir(repos[repoIndx]['full_name'].split('/')[-2])\n",
    "            print(repos[repoIndx]['full_name'].split('/')[-2])    \n",
    "            git.Git(repos[repoIndx]['full_name'].split('/')[-2]).clone(\"https:\"+gitsUrl.split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "while (res['items'] != []):\n",
    "    #print(res)\n",
    "    time.sleep(10)\n",
    "    total_count =res['total_count']\n",
    "    repoDic={}\n",
    "    repos=res['items']\n",
    "    for repoIndx in range(0, len(repos)):\n",
    "            repoName=repos[repoIndx]['full_name'].split('/')[1]\n",
    "            repoDic[repoName] = {}\n",
    "            repoDic[repoName]['desc']=repos[repoIndx]['description']\n",
    "            #We will the contents link for repo by using 'content_url' key.\n",
    "            contentsUrl = repos[repoIndx]['contents_url']   \n",
    "            contentsUrl=contentsUrl.split('{+path}')[0]\n",
    "            #Sending the request to get folders and files \n",
    "            gitReq=requests.get(contentsUrl,auth=('gess18','3de21fec1f9d02f5f573c7bf9224cc8f22c6abeb'))\n",
    "            contents=gitReq.json()\n",
    "            time.sleep(5)\n",
    "            for contentIndx in range(0,len(contents)):\n",
    "                    #print(contents)\n",
    "                    # Guessing the extensions of the files by mimtypes.\n",
    "                    typeGuess = mim.guess_type(contents[contentIndx]['name'])\n",
    "                    if(typeGuess[0] is not None):\n",
    "                            typeGuess=typeGuess[0].split('/')\n",
    "                            typeGuessImg=check_img(typeGuess)\n",
    "                            #print(typeGuessImg)\n",
    "                            typeGuess=check_text(typeGuess) or check_img(typeGuess)\n",
    "                    elif(contents[contentIndx]['type']=='file' and (re.search(contents[contentIndx]['name'],'description') or contents[contentIndx]['name']=='README')):\n",
    "                            typeGuess = typeGuess[0]\n",
    "                            gitReq=requests.get(contents[contentIndx]['git_url'],auth=('gess18','3de21fec1f9d02f5f573c7bf9224cc8f22c6abeb'))\n",
    "                            fileContent=gitReq.json()\n",
    "                            fileName=contents[contentIndx]['name']\n",
    "                            fileBytes=base64.b64decode(fileContent['content'])\n",
    "                            repoDic[repoName][fileName]=fileBytes.decode('utf-8')\n",
    "                            time.sleep(3)\n",
    "                            continue\n",
    "                    #print(typeGuess)        \n",
    "                    if(contents[contentIndx]['type']=='file' and typeGuess==True ):\n",
    "                        gitReq=requests.get(contents[contentIndx]['git_url'],auth=('gess18','3de21fec1f9d02f5f573c7bf9224cc8f22c6abeb'))\n",
    "                        fileName=contents[contentIndx]['name']\n",
    "                        fileContent=gitReq.json()\n",
    "                        fileBytes=base64.b64decode(fileContent['content'])\n",
    "                        #print(typeGuessImg)\n",
    "                        if(typeGuessImg):  \n",
    "                                #print(fileBytes)\n",
    "                                if(fileName.split('.')[-1] == 'SVG' or  fileName.split('.')[-1] == 'svg'):\n",
    "                                           continue\n",
    "                                imgFile=open('ImgToSave.'+fileName.split('.')[-1],'wb')\n",
    "                                #imgFile=open(fileName)\n",
    "                                imgFile.write(fileBytes)\n",
    "                                imgFile.close()\n",
    "                                #Extract the text from the image.\n",
    "                                '''\n",
    "                                imgFile=Image.open(fileName,'r').convert('RGB')\n",
    "                                pixels=np.asarray(imgFile,np.uint8)\n",
    "                                print(pixels.shape)\n",
    "                                convertedImg=abs(np.fft.rfft2(pixels,axes=(0,1)))\n",
    "                                print(convertedImg.shape)\n",
    "                                convertedImg=np.uint8(convertedImg)\n",
    "                                imgFile=Image.fromarray(convertedImg)\n",
    "                                imgFile.save(fileName)\n",
    "                                '''    \n",
    "                                if(fileName.split('.')[-1]=='png'or fileName.split('.')[-1]=='PNG'):\n",
    "                                            imgFile=Image.open('ImgToSave.'+fileName.split('.')[-1],'r').convert('RGB')\n",
    "                                            imgFile.save('ImgToSave.jpg')\n",
    "                                            fileName='ImgToSave.jpg'\n",
    "                                textOfImg=pytesseract.image_to_string(imread('ImgToSave.'+fileName.split('.')[-1]))\n",
    "                                repoDic[repoName][fileName]=textOfImg\n",
    "                        else:\n",
    "                                repoDic[repoName][fileName]=fileBytes.decode('utf-8')\n",
    "                                  \n",
    "                    elif(contents[contentIndx]['type']=='dir'): \n",
    "                                dirContents=requests.get(contents[contentIndx]['git_url']+'?recursive=-1',auth=('gess18','3de21fec1f9d02f5f573c7bf9224cc8f22c6abeb'))\n",
    "                                files= dirContents.json()['tree']\n",
    "                                #print(files)\n",
    "                                time.sleep(3)\n",
    "                                for fileIndx in range(len(files)):\n",
    "                                        #print(files[fileIndx])\n",
    "                                        if(files[fileIndx]['type']=='tree'):\n",
    "                                            continue\n",
    "                                        typeGuess = mim.guess_type(files[fileIndx]['path'])\n",
    "                                        if(typeGuess[0] is not None):\n",
    "                                            typeGuess=typeGuess[0].split('/')\n",
    "                                            #print(typeGuess)\n",
    "                                            typeGuessImg=check_img(typeGuess)    \n",
    "                                            typeGuess= check_text(typeGuess) or check_img(typeGuess)\n",
    "                                           \n",
    "                                        elif(files[fileIndx]['type']=='blob' and (re.search(files[fileIndx]['path'],'description') or files[fileIndx]['path'].split('/')[-1]=='README')):\n",
    "                                            typeGuess=typeGuess[0]\n",
    "                                            fileContent=requests.get(files[fileIndx]['url'],auth=('gess18','3de21fec1f9d02f5f573c7bf9224cc8f22c6abeb'))\n",
    "                                            fileName=files[fileIndx]['path'].split('/')[-1]\n",
    "                                            repoDic[repoName][fileName]=fileBytes.decode('utf-8')\n",
    "                                            time.sleep(3)\n",
    "                                            continue\n",
    "                                        print(files[fileIndx])    \n",
    "                                        if(files[fileIndx]['type']=='blob' and typeGuess==True):\n",
    "                                                fileContent=requests.get(files[fileIndx]['url'],auth=('gess18','3de21fec1f9d02f5f573c7bf9224cc8f22c6abeb')) \n",
    "                                                fileContent=fileContent.json()\n",
    "                                                #print(fileContent)\n",
    "                                                fileName=files[fileIndx]['path'].split('/')[-1]\n",
    "                                                fileBytes=base64.b64decode(fileContent['content']) \n",
    "                                                #print(typeGuessImg)\n",
    "                                                if(typeGuessImg):  \n",
    "                                                    #print(fileBytes)\n",
    "                                                    if(fileName.split('.')[-1] == 'SVG' or  fileName.split('.')[-1] == 'svg'):\n",
    "                                                             continue\n",
    "                                                    imgFile=open('ImgToSave.'+fileName.split('.')[-1],'wb')\n",
    "                                                    imgFile.write(fileBytes)\n",
    "                                                    imgFile.close()\n",
    "                                                    #Extract the text from the image.\n",
    "                                                    '''                                                    \n",
    "                                                    imgFile=Image.open(fileName,'r').convert('RGB')\n",
    "                                                    pixels=np.asarray(imgFile,np.uint8)\n",
    "                                                    print(pixels.shape)\n",
    "                                                    convertedImg=abs(np.fft.rfft2(pixels,axes=(0,1)))\n",
    "                                                    print(convertedImg.shape)\n",
    "                                                    convertedImg=np.uint8(convertedImg)\n",
    "                                                    imgFile=Image.fromarray(convertedImg)\n",
    "                                                    imgFile.save(fileName)\n",
    "                                                    '''    \n",
    "                                                    if(fileName.split('.')[-1]=='png'or fileName.split('.')[-1]=='PNG'):\n",
    "                                                            imgFile=Image.open('ImgToSave.'+fileName.split('.')[-1],'r').convert('RGB')\n",
    "                                                            imgFile.save('ImgToSave.jpg')\n",
    "                                                            fileName='ImgToSave.jpg'\n",
    "                                                            \n",
    "                                                    textOfImg=pytesseract.image_to_string(imread('ImgToSave.'+fileName.split('.')[-1]))\n",
    "                                                    \n",
    "                                                    repoDic[repoName][fileName]=textOfImg\n",
    "                                                else:\n",
    "                                                    repoDic[repoName][fileName]=fileBytes.decode('utf-8')\n",
    "                                                    \n",
    "                                                time.sleep(12)\n",
    "            repoFile = open(repoName,'w')\n",
    "            repoFile.write(str(repoDic))\n",
    "            repoFile.close()\n",
    "            repoDic={}\n",
    "    page +=1\n",
    "    req = requests.get('https://api.github.com/search/repositories?q=microservice+stars%3A521&type=Repositories&ref=advsearch&l=&l=+str(page)',auth=('gess18','3de21fec1f9d02f5f573c7bf9224cc8f22c6abeb'))\n",
    "    res = req.json()      \n",
    "    first=0\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Microservice repo contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['*\\\\n *  or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES *\\\\{\\'iot-device-simulator\\': {\\'desc\\': \\'The IoT Device Simulator solution is a Graphical User Interface (GUI) based engine designed to enable customers to get started quickly assessing AWS IoT services without an existing pool of devices. The IoT Device Simulator helps effortlessly create and simulate thousands of connected devices that are defined by the customer.\\', \\'app.js\\': \\'/*********************************************************************************************************************\\\\n *  Copyright 2016 Amazon.com, Inc. or its affiliates. All Rights Reserved.                                           *\\\\n *                                                                                                                    *\\\\n *  Licensed under the Amazon Software License (the \"License\"). You may not use this file except in compliance        *\\\\n *  with the License. A copy of the License is located at                                                             *\\\\n *                                                                                                                    *\\\\n *      http://aws.amazon.com/asl/                                                                                    *\\\\n *                     n *  OR CONDITIONS OF ANY KIND, express or implied. See the License for the specific language governing permissions    *\\\\n *  and limitations under the License.                                                                                *\\\\n *********************************************************************************************************************/\\\\n\\\\n/**\\\\n * @author Solution Builders\\\\n */\\\\n\\\\n\\\\\\'use strict\\\\\\';\\\\n\\\\nconst fs = require(\\\\\\'fs\\\\\\');\\\\nconst path = require(\\\\\\'path\\\\\\');\\\\nconst args = require(\\\\\\'minimist\\\\\\')(process.argv.slice(2));\\\\n\\\\nlet getFileList = function(path) {\\\\n    let fileInfo;\\\\n    let filesFound;\\\\n    let fileList = [];\\\\n\\\\n    filesFound = fs.readdirSync(path);\\\\n    for (let i = 0; i < filesFound.length; i++) {\\\\n        fileInfo = fs.lstatSync([path, filesFound[i]].join(\\\\\\'/\\\\\\'));\\\\n        if (fileInfo.isFile()) {\\\\n            fileList.push(filesFound[i]);\\\\n        }\\\\n\\\\n        if (fileInfo.isDirectory()) {\\\\n            console.log([path, filesFound[i]].join(\\\\\\'/\\\\\\'));\\\\n        }\\\\n    }\\\\n\\\\n    return fileList;\\\\n};\\\\n\\\\n// List all files in a directory in Node.js recursively in a synchronous fashion\\\\nlet walkSync = function(dir, filelist) {\\\\n    // let filelist = []; //getFileList(\\\\\\'./temp/site\\\\\\');\\\\n    let files = fs.readdirSync(dir);\\\\n    filelist = filelist || [];\\\\n    files.forEach(function(file) {\\\\n        if \\n', '\\n', \"'a',\\n\", \" 'about',\\n\", \" 'above',\\n\", \" 'after',\\n\", \" 'again',\\n\", \" 'against',\\n\", \" 'ain',\\n\", \" 'all',\\n\", \" 'am',\\n\", \" 'an',\\n\", \" 'and',\\n\", \" 'any',\\n\", \" 'are',\\n\", \" 'aren',\\n\", ' \"aren\\'t\",\\n', \" 'as',\\n\", \" 'at',\\n\", \" 'be',\\n\", \" 'because',\\n\", \" 'been',\\n\", \" 'before',\\n\", \" 'being',\\n\", \" 'below',\\n\", \" 'between',\\n\", \" 'both',\\n\", \" 'but',\\n\", \" 'by',\\n\", \" 'can',\\n\", \" 'couldn',\\n\", ' \"couldn\\'t\",\\n', \" 'd',\\n\", \" 'did',\\n\", \" 'didn',\\n\", ' \"didn\\'t\",\\n', \" 'do',\\n\", \" 'does',\\n\", \" 'doesn',\\n\", ' \"doesn\\'t\",\\n', \" 'doing',\\n\", \" 'don',\\n\", ' \"don\\'t\",\\n', \" 'down',\\n\", \" 'during',\\n\", \" 'each',\\n\", \" 'few',\\n\", \" 'for',\\n\", \" 'from',\\n\", \" 'further',\\n\", \" 'had',\\n\", \" 'hadn',\\n\", ' \"hadn\\'t\",\\n', \" 'has',\\n\", \" 'hasn',\\n\", ' \"hasn\\'t\",\\n', \" 'have',\\n\", \" 'haven',\\n\", ' \"haven\\'t\",\\n', \" 'having',\\n\", \" 'he',\\n\", \" 'her',\\n\", \" 'here',\\n\", \" 'hers',\\n\", \" 'herself',\\n\", \" 'him',\\n\", \" 'himself',\\n\", \" 'his',\\n\", \" 'how',\\n\", \" 'i',\\n\", \" 'if',\\n\", \" 'in',\\n\", \" 'into',\\n\", \" 'is',\\n\", \" 'isn',\\n\", ' \"isn\\'t\",\\n', \" 'it',\\n\", ' \"it\\'s\",\\n', \" 'its',\\n\", \" 'itself',\\n\", \" 'just',\\n\", \" 'll',\\n\", \" 'm',\\n\", \" 'ma',\\n\", \" 'me',\\n\", \" 'mightn',\\n\", ' \"mightn\\'t\",\\n', \" 'more',\\n\", \" 'most',\\n\", \" 'mustn',\\n\", ' \"mustn\\'t\",\\n', \" 'my',\\n\", \" 'myself',\\n\", \" 'needn',\\n\", ' \"needn\\'t\",\\n', \" 'no',\\n\", \" 'nor',\\n\", \" 'not',\\n\", \" 'now',\\n\", \" 'o',\\n\", \" 'of',\\n\", \" 'off',\\n\", \" 'on',\\n\", \" 'once',\\n\", \" 'only',\\n\", \" 'or',\\n\", \" 'other',\\n\", \" 'our',\\n\", \" 'ours',\\n\", \" 'ourselves',\\n\", \" 'out',\\n\", \" 'over',\\n\", \" 'own',\\n\", \" 're',\\n\", \" 's',\\n\", \" 'same',\\n\", \" 'shan',\\n\", ' \"shan\\'t\",\\n', \" 'she',\\n\", ' \"she\\'s\",\\n', \" 'should',\\n\", ' \"should\\'ve\",\\n', \" 'shouldn',\\n\", ' \"shouldn\\'t\",\\n', \" 'so',\\n\", \" 'some',\\n\", \" 'such',\\n\", \" 't',\\n\", \" 'than',\\n\", \" 'that',\\n\", ' \"that\\'ll\",\\n', \" 'the',\\n\", \" 'their',\\n\", \" 'theirs',\\n\", \" 'them',\\n\", \" 'themselves',\\n\", \" 'then',\\n\", \" 'there',\\n\", \" 'these',\\n\", \" 'they',\\n\", \" 'this',\\n\", \" 'those',\\n\", \" 'through',\\n\", \" 'to',\\n\", \" 'too',\\n\", \" 'under',\\n\", \" 'until',\\n\", \" 'up',\\n\", \" 've',\\n\", \" 'very',\\n\", \" 'was',\\n\", \" 'wasn',\\n\", ' \"wasn\\'t\",\\n', \" 'we',\\n\", \" 'were',\\n\", \" 'weren',\\n\", ' \"weren\\'t\",\\n', \" 'what',\\n\", \" 'when',\\n\", \" 'where',\\n\", \" 'which',\\n\", \" 'while',\\n\", \" 'who',\\n\", \" 'whom',\\n\", \" 'why',\\n\", \" 'will',\\n\", \" 'with',\\n\", \" 'won',\\n\", ' \"won\\'t\",\\n', \" 'wouldn',\\n\", ' \"wouldn\\'t\",\\n', \" 'y',\\n\", \" 'you',\\n\", ' \"you\\'d\",\\n', ' \"you\\'ll\",\\n', ' \"you\\'re\",\\n', ' \"you\\'ve\",\\n', \" 'your',\\n\", \" 'yours',\\n\", \" 'yourself',\\n\", \" 'yourselves'}\"]\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/gleschen/Downloads/test_raw_file.txt\"\n",
    "file=open(path,'r')\n",
    "print(file.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n  orinthe  license  fileaccompanyingthisfile  Thisfileisdistributedonan  ASIS  BASIS  WITHOUTWARRANTIES        iot  device  simulator        desc      TheIoTDeviceSimulatorsolutionisaGraphicalUserInterface  GUI  basedenginedesignedtoenablecustomerstogetstartedquicklyassessingAWSIoTserviceswithoutanexistingpoolofdevices  TheIoTDeviceSimulatorhelpseffortlesslycreateandsimulatethousandsofconnecteddevicesthataredefinedbythecustomer        app  js                                                                                                                                                                                                                                                    n  Copyright        Amazon  com  Inc  oritsaffiliates  AllRightsReserved      n      n  LicensedundertheAmazonSoftwareLicense  the  License      Youmaynotusethisfileexceptincompliance    n  withtheLicense  AcopyoftheLicenseislocatedat    n      n  http      aws  amazon  com  asl      n  n  ORCONDITIONSOFANYKIND  expressorimplied  SeetheLicenseforthespecificlanguagegoverningpermissions    n  andlimitationsundertheLicense      n                                                                                                                                                                                                                                              n  n        n    authorSolutionBuilders  n      n  n    usestrict        n  nconstfs  require      fs          nconstpath  require      path          nconstargs  require      minimist        process  argv  slice            n  nletgetFileList  function  path      nletfileInfo    nletfilesFound    nletfileList          n  nfilesFound  fs  readdirSync  path      nfor  leti      i  filesFound  length  i          nfileInfo  fs  lstatSync    path  filesFound  i      join                    nif  fileInfo  isFile          nfileList  push  filesFound  i        n    n  nif  fileInfo  isDirectory          nconsole  log    path  filesFound  i      join                    n    n    n  nreturnfileList    n      n  n    ListallfilesinadirectoryinNode  jsrecursivelyinasynchronousfashion  nletwalkSync  function  dir  filelist      n    letfilelist            getFileList          temp  site          nletfiles  fs  readdirSync  dir      nfilelist  filelist            nfiles  forEach  function  file      nif  a      about      above      after      again      against      ain      all      am      an      and      any      are      aren      aren  t      as      at      be      because      been      before      being      below      between      both      but      by      can      couldn      couldn  t      d      did      didn      didn  t      do      does      doesn      doesn  t      doing      don      don  t      down      during      each      few      for      from      further      had      hadn      hadn  t      has      hasn      hasn  t      have      haven      haven  t      having      he      her      here      hers      herself      him      himself      his      how      i      if      in      into      is      isn      isn  t      it      it  s      its      itself      just      ll      m      ma      me      mightn      mightn  t      more      most      mustn      mustn  t      my      myself      needn      needn  t      no      nor      not      now      o      of      off      on      once      only      or      other      our      ours      ourselves      out      over      own      re      s      same      shan      shan  t      she      she  s      should      should  ve      shouldn      shouldn  t      so      some      such      t      than      that      that  ll      the      their      theirs      them      themselves      then      there      these      they      this      those      through      to      too      under      until      up      ve      very      was      wasn      wasn  t      we      were      weren      weren  t      what      when      where      which      while      who      whom      why      will      with      won      won  t      wouldn      wouldn  t      y      you      you  d      you  ll      you  re      you  ve      your      yours      yourself      yourselves    \n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/gleschen/Downloads/test_raw_file.txt\"\n",
    "file=open(path,'r')\n",
    "lines=file.readlines()\n",
    "cummulateString=''\n",
    "for line in lines:\n",
    "#print(newLine)\n",
    "    for char in line:\n",
    "# Exclude the non alphabitical data.\n",
    "        if(char.isalpha()):\n",
    "            cummulateString+=char\n",
    "        elif(char.isspace()):\n",
    "            cummulateString+=''\n",
    "        elif(char.isupper()):\n",
    "            char=char.lower()\n",
    "            cummulateString+=char\n",
    "        else:\n",
    "            cummulateString+=' '\n",
    "            cummulateString+=' '\n",
    "print(cummulateString)\n",
    "#file.close()\n",
    "cummulateString+=' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n', 'orinthe', 'license', 'fileaccompanyingthisfile', 'Thisfileisdistributedonan', 'ASIS', 'BASIS', 'WITHOUTWARRANTIES', 'iot', 'device', 'simulator', 'desc', 'TheIoTDeviceSimulatorsolutionisaGraphicalUserInterface', 'GUI', 'basedenginedesignedtoenablecustomerstogetstartedquicklyassessingAWSIoTserviceswithoutanexistingpoolofdevices', 'TheIoTDeviceSimulatorhelpseffortlesslycreateandsimulatethousandsofconnecteddevicesthataredefinedbythecustomer', 'app', 'js', 'n', 'Copyright', 'Amazon', 'com', 'Inc', 'oritsaffiliates', 'AllRightsReserved', 'n', 'n', 'LicensedundertheAmazonSoftwareLicense', 'the', 'License', 'Youmaynotusethisfileexceptincompliance', 'n', 'withtheLicense', 'AcopyoftheLicenseislocatedat', 'n', 'n', 'http', 'aws', 'amazon', 'com', 'asl', 'n', 'n', 'ORCONDITIONSOFANYKIND', 'expressorimplied', 'SeetheLicenseforthespecificlanguagegoverningpermissions', 'n', 'andlimitationsundertheLicense', 'n', 'n', 'n', 'n', 'authorSolutionBuilders', 'n', 'n', 'n', 'usestrict', 'n', 'nconstfs', 'require', 'fs', 'nconstpath', 'require', 'path', 'nconstargs', 'require', 'minimist', 'process', 'argv', 'slice', 'n', 'nletgetFileList', 'function', 'path', 'nletfileInfo', 'nletfilesFound', 'nletfileList', 'n', 'nfilesFound', 'fs', 'readdirSync', 'path', 'nfor', 'leti', 'i', 'filesFound', 'length', 'i', 'nfileInfo', 'fs', 'lstatSync', 'path', 'filesFound', 'i', 'join', 'nif', 'fileInfo', 'isFile', 'nfileList', 'push', 'filesFound', 'i', 'n', 'n', 'nif', 'fileInfo', 'isDirectory', 'nconsole', 'log', 'path', 'filesFound', 'i', 'join', 'n', 'n', 'n', 'nreturnfileList', 'n', 'n', 'n', 'ListallfilesinadirectoryinNode', 'jsrecursivelyinasynchronousfashion', 'nletwalkSync', 'function', 'dir', 'filelist', 'n', 'letfilelist', 'getFileList', 'temp', 'site', 'nletfiles', 'fs', 'readdirSync', 'dir', 'nfilelist', 'filelist', 'nfiles', 'forEach', 'function', 'file', 'nif', 'a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', 'aren', 't', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', 'couldn', 't', 'd', 'did', 'didn', 'didn', 't', 'do', 'does', 'doesn', 'doesn', 't', 'doing', 'don', 'don', 't', 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', 'hadn', 't', 'has', 'hasn', 'hasn', 't', 'have', 'haven', 'haven', 't', 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', 'isn', 't', 'it', 'it', 's', 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', 'mightn', 't', 'more', 'most', 'mustn', 'mustn', 't', 'my', 'myself', 'needn', 'needn', 't', 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', 'shan', 't', 'she', 'she', 's', 'should', 'should', 've', 'shouldn', 'shouldn', 't', 'so', 'some', 'such', 't', 'than', 'that', 'that', 'll', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', 'wasn', 't', 'we', 'were', 'weren', 'weren', 't', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', 'won', 't', 'wouldn', 'wouldn', 't', 'y', 'you', 'you', 'd', 'you', 'll', 'you', 're', 'you', 've', 'your', 'yours', 'yourself', 'yourselves']\n",
      "['n', 'orinthe', 'license', 'fileaccompanyingthisfile', 'Thisfileisdistributedonan', 'ASIS', 'BASIS', 'WITHOUTWARRANTIES', 'iot', 'device', 'simulator', 'desc', 'TheIoTDeviceSimulatorsolutionisaGraphicalUserInterface', 'GUI', 'basedenginedesignedtoenablecustomerstogetstartedquicklyassessingAWSIoTserviceswithoutanexistingpoolofdevices', 'TheIoTDeviceSimulatorhelpseffortlesslycreateandsimulatethousandsofconnecteddevicesthataredefinedbythecustomer', 'app', 'js', 'n', 'Copyright', 'Amazon', 'com', 'Inc', 'oritsaffiliates', 'AllRightsReserved', 'n', 'n', 'LicensedundertheAmazonSoftwareLicense', 'License', 'Youmaynotusethisfileexceptincompliance', 'n', 'withtheLicense', 'AcopyoftheLicenseislocatedat', 'n', 'n', 'http', 'aws', 'amazon', 'com', 'asl', 'n', 'n', 'ORCONDITIONSOFANYKIND', 'expressorimplied', 'SeetheLicenseforthespecificlanguagegoverningpermissions', 'n', 'andlimitationsundertheLicense', 'n', 'n', 'n', 'n', 'authorSolutionBuilders', 'n', 'n', 'n', 'usestrict', 'n', 'nconstfs', 'require', 'fs', 'nconstpath', 'require', 'path', 'nconstargs', 'require', 'minimist', 'process', 'argv', 'slice', 'n', 'nletgetFileList', 'function', 'path', 'nletfileInfo', 'nletfilesFound', 'nletfileList', 'n', 'nfilesFound', 'fs', 'readdirSync', 'path', 'nfor', 'leti', 'filesFound', 'length', 'nfileInfo', 'fs', 'lstatSync', 'path', 'filesFound', 'join', 'nif', 'fileInfo', 'isFile', 'nfileList', 'push', 'filesFound', 'n', 'n', 'nif', 'fileInfo', 'isDirectory', 'nconsole', 'log', 'path', 'filesFound', 'join', 'n', 'n', 'n', 'nreturnfileList', 'n', 'n', 'n', 'ListallfilesinadirectoryinNode', 'jsrecursivelyinasynchronousfashion', 'nletwalkSync', 'function', 'dir', 'filelist', 'n', 'letfilelist', 'getFileList', 'temp', 'site', 'nletfiles', 'fs', 'readdirSync', 'dir', 'nfilelist', 'filelist', 'nfiles', 'forEach', 'function', 'file', 'nif']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "'''\n",
    "def remove_stopwords(cummulateString):\n",
    "        processed_word_list = []\n",
    "        for word in cummulateString:\n",
    "            word = word.lower() # in case they aren't all lower case\n",
    "            if word not in stopwords.words(\"english\"):\n",
    "                processed_word_list.append(word)\n",
    "        print (cummulateString)\n",
    "        return processed_word_list\n",
    "'''\n",
    "#example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "word_tokens = word_tokenize(cummulateString)  \n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]  \n",
    "filtered_sentence = [] \n",
    "for w in word_tokens: \n",
    "    if w not in stop_words: \n",
    "        filtered_sentence.append(w) \n",
    "print(word_tokens) \n",
    "print(filtered_sentence) \n",
    "with open('cleaned_data.txt', 'w') as f:\n",
    "    print(filtered_sentence, file=f)  \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Contents for Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import mmap\n",
    "with open('cleaned_data.txt') as f:\n",
    "    s = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "    if s.find(b'IoT'or b'device' or b'automotive' or b'vehicle' or b'car') != -1:\n",
    "        print(\"Microservice is classified as: Automotive\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Banking Automotive    Media  Fintech  Transportation  Law  \\\n",
      "0              bank        iot  netflix  fintech  transportation  law   \n",
      "1          mortgage     device       no       no              no   no   \n",
      "2  checking account         no       no       no              no   no   \n",
      "\n",
      "  Food&Beverages Healthcare Education   Real Estate  Insurance       Energy  \\\n",
      "0       beverage     health    school  construction  insurance  electricity   \n",
      "1             no         no        no            no         no           no   \n",
      "2             no         no        no            no         no           no   \n",
      "\n",
      "   Retail  Encryption  Monitoring  Search  Authentication  Logging  Upload  \\\n",
      "0  retail  encryption        siem  search  authentication  logging  upload   \n",
      "1      no  decryption  monitoring      no              no       no      no   \n",
      "2      no          no          no      no              no       no      no   \n",
      "\n",
      "  Other  \n",
      "0    no  \n",
      "1    no  \n",
      "2    no  \n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('/Users/gleschen/Downloads/dictionary.csv')\n",
    "df = df.fillna('no')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import csv\n",
    "#reader = csv.DictReader(open(\"file2.csv\"))\n",
    "df = csv.DictReader(open(\"/Users/gleschen/Downloads/dictionary.csv\"))\n",
    "for raw in df:\n",
    "    orderedDict = raw\n",
    "    #print(raw)\n",
    "    print (raw)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(orderedDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orderedDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-12646ea5f202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/gleschen/Downloads/cleaned_data.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACCESS_READ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morderedDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'orderedDict' is not defined"
     ]
    }
   ],
   "source": [
    "import mmap\n",
    "with open('/Users/gleschen/Downloads/cleaned_data.txt') as f:\n",
    "    s = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "    dic = orderedDict.values()\n",
    "    print(list(dic))\n",
    "    d = list(dic)\n",
    "    #if s.find(b'dic') != -1:\n",
    "    print(s.find(bytes(d[1].encode('utf-8'))))\n",
    "    #print(\"Microservice is classified as: Automotive\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This microservice is classified as: Banking\n",
      "This microservice is classified as: Banking\n",
      "This microservice is classified as: Banking\n",
      "This microservice is classified as: Automotive\n",
      "This microservice is classified as: Automotive\n",
      "This microservice is classified as: Automotive\n",
      "This microservice is classified as: Media\n",
      "This microservice is classified as: Media\n",
      "This microservice is classified as: Fintech\n",
      "This microservice is classified as: Fintech\n",
      "This microservice is classified as: Transportation\n",
      "This microservice is classified as: Transportation\n",
      "This microservice is classified as: Law\n",
      "This microservice is classified as: Law\n",
      "This microservice is classified as: Food&Beverages\n",
      "This microservice is classified as: Food&Beverages\n",
      "This microservice is classified as: Healthcare\n",
      "This microservice is classified as: Healthcare\n",
      "This microservice is classified as: Education\n",
      "This microservice is classified as: Education\n",
      "This microservice is classified as: Real Estate\n",
      "This microservice is classified as: Real Estate\n",
      "This microservice is classified as: Insurance\n",
      "This microservice is classified as: Insurance\n",
      "This microservice is classified as: Energy\n",
      "This microservice is classified as: Energy\n",
      "This microservice is classified as: Retail\n",
      "This microservice is classified as: Retail\n",
      "This microservice is classified as: Encryption\n",
      "This microservice is classified as: Monitoring\n",
      "This microservice is classified as: Monitoring\n",
      "This microservice is classified as: Monitoring\n",
      "This microservice is classified as: Search\n",
      "This microservice is classified as: Search\n",
      "This microservice is classified as: Authentication\n",
      "This microservice is classified as: Authentication\n",
      "This microservice is classified as: Logging\n",
      "This microservice is classified as: Logging\n",
      "This microservice is classified as: Upload\n",
      "This microservice is classified as: Upload\n",
      "This microservice is classified as: Other\n",
      "This microservice is classified as: Other\n",
      "This microservice is classified as: Other\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/gleschen/Downloads/_huge_Java-Bank-Project.txt') as f:\n",
    "    cleanedData=f.read()\n",
    "    for col in df.columns:\n",
    "        for indx in range(0,len(df.loc[:,col])):\n",
    "          if df.loc[:,col][indx] in cleanedData:\n",
    "            #print(key.d[0])\n",
    "            #print([key for key in raw.keys()][0])\n",
    "            print(\"This microservice is classified as:\", col)\n",
    "            #print(\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "import ast\n",
    "countDic ={}\n",
    "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
    "with open('/Users/gleschen/Downloads/cleaned_data.txt') as f:\n",
    "    cleanedData=f.read()\n",
    "    for col in df.columns:\n",
    "        countDic[col]={}\n",
    "        for indx in range(0,len(df.loc[:,col])):         \n",
    "          print(df.loc[:,col][indx])\n",
    "          if df.loc[:,col][indx] in cleanedData and df.loc[:,col][indx]!='no':\n",
    "            countDic[col] +=1    \n",
    "            cleanedatalist = ast.literal_eval(cleanedData)\n",
    "            t=Tokenizer()\n",
    "            t.fit_on_texts(cleanedatalist)\n",
    "            print(\"Keyword:\", df.loc[:,col][indx], \"\\nOccurrence:\", t.word_counts[df.loc[:,col][indx]])\n",
    "            #print(text_to_word_sequence(cleanedData))\n",
    "            #print(key.d[0])\n",
    "            #print([key for key in raw.keys()][0])\n",
    "            print(\"This microservice is classified as:\", col)\n",
    "            #print(\"true\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank\n",
      "device\n",
      "search\n",
      "authentication\n",
      "logging\n",
      "upload\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "countDic ={}\n",
    "countDic['Topic']={}\n",
    "countDic['Topic']['H']={}\n",
    "countDic['Topic']['V']={}\n",
    "type_1='V'\n",
    "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
    "with open('/Users/gleschen/Downloads/_huge_Java-Bank-Project') as f:\n",
    "    cleanedData=f.read()\n",
    "    for indxCol in range(0,len(df.columns)):\n",
    "        if(indxCol < 13):\n",
    "            #print(df.columns[indxCol])\n",
    "            countDic['Topic'][type_1][df.columns[indxCol]]=0\n",
    "        else:\n",
    "            type_1='H'\n",
    "            countDic['Topic'][type_1][df.columns[indxCol]]=0\n",
    "        for indx in range(0,len(df.loc[:,df.columns[indxCol]])): \n",
    "          #print(df.loc[:,df.columns[indxCol]][indx])\n",
    "          if df.loc[:,df.columns[indxCol]][indx] in cleanedData and df.loc[:,df.columns[indxCol]][indx]!='no':\n",
    "            countDic['Topic'][type_1][df.columns[indxCol]]+=1\n",
    "            #print(countDic['Topic'][type_1][df.columns[indxCol]])\n",
    "            print(df.loc[:,df.columns[indxCol]][indx])\n",
    "            cleanedatalist = ast.literal_eval(cleanedData)\n",
    "            t=Tokenizer()\n",
    "            t.fit_on_texts(cleanedatalist)\n",
    "            #print(\"Keyword:\", df.loc[:,df.columns[indxCol]][indx], \"\\nOccurrence:\", t.word_counts[df.loc[:,df.columns[indxCol]][indx]])\n",
    "            #print(text_to_word_sequence(cleanedData))\n",
    "            #print(key.d[0])\n",
    "            #print([key for key in raw.keys()][0])\n",
    "            #print(\"This microservice is classified as:\", df.columns[indxCol])\n",
    "            #print(\"true\")countDic['horizontal']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Topic': {'H': {'Encryption': 0,\n",
       "   'Monitoring': 0,\n",
       "   'Search': 1,\n",
       "   'Authentication': 1,\n",
       "   'Logging': 1,\n",
       "   'Upload': 1,\n",
       "   'Other': 0},\n",
       "  'V': {'Banking': 1,\n",
       "   'Automotive': 1,\n",
       "   'Media': 0,\n",
       "   'Fintech': 0,\n",
       "   'Transportation': 0,\n",
       "   'Law': 0,\n",
       "   'Food&Beverages': 0,\n",
       "   'Healthcare': 0,\n",
       "   'Education': 0,\n",
       "   'Real Estate': 0,\n",
       "   'Insurance': 0,\n",
       "   'Energy': 0,\n",
       "   'Retail': 0}}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search\n",
      "Authentication\n",
      "Banking\n",
      "Automotive\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "lblwithkeywordsH = countDic['Topic']['H']\n",
    "lblwithkeywordsV = countDic['Topic']['V']\n",
    "lblwithkeywordsH = collections.Counter(lblwithkeywordsH)\n",
    "lblwithkeywordsV = collections.Counter(lblwithkeywordsV)\n",
    "dH = lblwithkeywordsH.most_common(2)\n",
    "dV = lblwithkeywordsV.most_common(2)\n",
    "\n",
    "for key,value in dH:\n",
    "    print(key)\n",
    "for key,value in dV:\n",
    "    print(key)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "HList=[]\n",
    "VList=[]\n",
    "for key in countDic['Topic']['H']:\n",
    "  if(countDic['Topic']['H'][key]==max(countDic['Topic']['H'].values())):\n",
    "    HList+=[key]\n",
    "for key in countDic['Topic']['V']:\n",
    "  if(countDic['Topic']['V'][key]==max(countDic['Topic']['V'].values())): \n",
    "    VList+=[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This microservice is classified as: ['Search', 'Authentication', 'Logging', 'Upload'] ['Banking', 'Automotive']\n"
     ]
    }
   ],
   "source": [
    "print(\"This microservice is classified as:\",HList,VList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(countDic['Topic']['H'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
